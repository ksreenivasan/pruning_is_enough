{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8e19fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nonzeros(model, print_flag=False):\n",
    "    nonzero = 0\n",
    "    total = 0\n",
    "    per_layer_sparsity = []\n",
    "    for name, p in model.named_parameters():\n",
    "        if 'weight' in name and 'ft' not in name:\n",
    "            tensor = p.data.cpu().numpy()\n",
    "            nz_count = np.count_nonzero(tensor)\n",
    "            total_params = np.prod(tensor.shape)\n",
    "            nonzero += nz_count\n",
    "            total += total_params\n",
    "            if print_flag:\n",
    "                print(f'{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | total_pruned = {total_params - nz_count :7} | shape = {tensor.shape}')\n",
    "                per_layer_sparsity.append(100 * nz_count / total_params)\n",
    "    if print_flag:\n",
    "        print(f'alive: {nonzero}, pruned : {total - nonzero}, total: {total}, ({100 * nonzero / total:6.2f}% remained)')\n",
    "    return per_layer_sparsity  # (round((nonzero/total)*100, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf751f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "097dac5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Reading YAML config from configs/hypercube/resnet20/resnet20_base.yml\n"
     ]
    }
   ],
   "source": [
    "# get the config file correctly\n",
    "\n",
    "from main_utils import *\n",
    "\n",
    "# parser_args.config = \"configs/hypercube/resnet20/resnet32_sr.yml\"\n",
    "# parser_args.subfolder = \"target_sparsity_20_smart_ratio2\"\n",
    "# parser_args.subfolder = \"target_sparsity_100_lr_0_1\"\n",
    "# ========== # \n",
    "# parser_args.subfolder = \"tmp_hc_sc\"  # \"tmp_imp\"\n",
    "# model_filename = \"tmp_hc_ckpt_sc.pt\"  # \"tmp_imp_ckpt.pt\"\n",
    "# PATH = \"tmp_hc.pt\"  # \"tmp_imp.pt\"\n",
    "parser_args.algo = 'hc_iter'\n",
    "# ========== #\n",
    "# parser_args.init = \"signed_constant\"  # \"kaiming_normal\"\n",
    "parser_args.arch = \"resnet20\"\n",
    "# parser_args.smart_ratio = 0.98\n",
    "# parser_args.fine_tune_lr = 0.1\n",
    "# parser_args.gpu = 0\n",
    "# parser_args.random_network_per_layer_ratio = [100., 100., 100., 100., 100.,100.,100.,100.,100.,100.,100.,100.,100.,100.,100.,100.,100.,100.,100.,100.,100.]\n",
    "# parser_args.random_subnet = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b3cdecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Creating model 'resnet20'\n",
      "==> Conv Type: SubnetConv\n",
      "==> BN Type: NonAffineBatchNorm\n",
      "==> Building first layer\n",
      "==> Setting prune rate of network to 0.5\n",
      "=> Rough estimate model params 268336\n",
      "=> Freezing model weights\n"
     ]
    }
   ],
   "source": [
    "model = get_model(parser_args)\n",
    "PATH = \"results/target_sparsity_50//results_pruning_CIFAR10_resnet20_hc_iter_0_5_8_reg_L2_1e-08_sgd_cosine_lr_0_05_0_1_50_finetune_0_1_MAML_-1_10_fan_False_signed_constant_unif_width_1_0_seed_42_idx_None/model_after_finetune.pth\"\n",
    "ckpt = torch.load(PATH)\n",
    "model.load_state_dict(ckpt)\n",
    "model = set_gpu(parser_args, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "503969e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Getting CIFAR10 dataset\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90.07"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, target in test_loader:\n",
    "            x, target = x.to(device), target.to(device)\n",
    "            output = model(x)\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_acc = 100. * correct/len(test_loader.dataset)\n",
    "    return test_acc\n",
    "\n",
    "\n",
    "data = get_dataset(parser_args)\n",
    "test(model, \"cuda\", data.val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35b5dc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight         | nonzeros =      67 /     432 ( 15.51%) | total_pruned =     365 | shape = (16, 3, 3, 3)\n",
      "layer1.0.conv1.weight | nonzeros =     337 /    2304 ( 14.63%) | total_pruned =    1967 | shape = (16, 16, 3, 3)\n",
      "layer1.0.conv2.weight | nonzeros =     316 /    2304 ( 13.72%) | total_pruned =    1988 | shape = (16, 16, 3, 3)\n",
      "layer1.1.conv1.weight | nonzeros =     295 /    2304 ( 12.80%) | total_pruned =    2009 | shape = (16, 16, 3, 3)\n",
      "layer1.1.conv2.weight | nonzeros =     276 /    2304 ( 11.98%) | total_pruned =    2028 | shape = (16, 16, 3, 3)\n",
      "layer1.2.conv1.weight | nonzeros =     257 /    2304 ( 11.15%) | total_pruned =    2047 | shape = (16, 16, 3, 3)\n",
      "layer1.2.conv2.weight | nonzeros =     238 /    2304 ( 10.33%) | total_pruned =    2066 | shape = (16, 16, 3, 3)\n",
      "layer1.3.conv1.weight | nonzeros =     221 /    2304 (  9.59%) | total_pruned =    2083 | shape = (16, 16, 3, 3)\n",
      "layer1.3.conv2.weight | nonzeros =     204 /    2304 (  8.85%) | total_pruned =    2100 | shape = (16, 16, 3, 3)\n",
      "layer1.4.conv1.weight | nonzeros =     187 /    2304 (  8.12%) | total_pruned =    2117 | shape = (16, 16, 3, 3)\n",
      "layer1.4.conv2.weight | nonzeros =     172 /    2304 (  7.47%) | total_pruned =    2132 | shape = (16, 16, 3, 3)\n",
      "layer2.0.conv1.weight | nonzeros =     314 /    4608 (  6.81%) | total_pruned =    4294 | shape = (32, 16, 3, 3)\n",
      "layer2.0.conv2.weight | nonzeros =     571 /    9216 (  6.20%) | total_pruned =    8645 | shape = (32, 32, 3, 3)\n",
      "layer2.1.conv1.weight | nonzeros =     517 /    9216 (  5.61%) | total_pruned =    8699 | shape = (32, 32, 3, 3)\n",
      "layer2.1.conv2.weight | nonzeros =     465 /    9216 (  5.05%) | total_pruned =    8751 | shape = (32, 32, 3, 3)\n",
      "layer2.2.conv1.weight | nonzeros =     416 /    9216 (  4.51%) | total_pruned =    8800 | shape = (32, 32, 3, 3)\n",
      "layer2.2.conv2.weight | nonzeros =     370 /    9216 (  4.01%) | total_pruned =    8846 | shape = (32, 32, 3, 3)\n",
      "layer2.3.conv1.weight | nonzeros =     326 /    9216 (  3.54%) | total_pruned =    8890 | shape = (32, 32, 3, 3)\n",
      "layer2.3.conv2.weight | nonzeros =     285 /    9216 (  3.09%) | total_pruned =    8931 | shape = (32, 32, 3, 3)\n",
      "layer2.4.conv1.weight | nonzeros =     247 /    9216 (  2.68%) | total_pruned =    8969 | shape = (32, 32, 3, 3)\n",
      "layer2.4.conv2.weight | nonzeros =     212 /    9216 (  2.30%) | total_pruned =    9004 | shape = (32, 32, 3, 3)\n",
      "layer3.0.conv1.weight | nonzeros =     359 /   18432 (  1.95%) | total_pruned =   18073 | shape = (64, 32, 3, 3)\n",
      "layer3.0.conv2.weight | nonzeros =     598 /   36864 (  1.62%) | total_pruned =   36266 | shape = (64, 64, 3, 3)\n",
      "layer3.1.conv1.weight | nonzeros =     489 /   36864 (  1.33%) | total_pruned =   36375 | shape = (64, 64, 3, 3)\n",
      "layer3.1.conv2.weight | nonzeros =     391 /   36864 (  1.06%) | total_pruned =   36473 | shape = (64, 64, 3, 3)\n",
      "layer3.2.conv1.weight | nonzeros =     304 /   36864 (  0.82%) | total_pruned =   36560 | shape = (64, 64, 3, 3)\n",
      "layer3.2.conv2.weight | nonzeros =     228 /   36864 (  0.62%) | total_pruned =   36636 | shape = (64, 64, 3, 3)\n",
      "layer3.3.conv1.weight | nonzeros =     163 /   36864 (  0.44%) | total_pruned =   36701 | shape = (64, 64, 3, 3)\n",
      "layer3.3.conv2.weight | nonzeros =     108 /   36864 (  0.29%) | total_pruned =   36756 | shape = (64, 64, 3, 3)\n",
      "layer3.4.conv1.weight | nonzeros =      65 /   36864 (  0.18%) | total_pruned =   36799 | shape = (64, 64, 3, 3)\n",
      "layer3.4.conv2.weight | nonzeros =      32 /   36864 (  0.09%) | total_pruned =   36832 | shape = (64, 64, 3, 3)\n",
      "fc.weight            | nonzeros =     192 /     640 ( 30.00%) | total_pruned =     448 | shape = (10, 64, 1, 1)\n",
      "alive: 9222, pruned : 452650, total: 461872, (  2.00% remained)\n"
     ]
    }
   ],
   "source": [
    "(conv_layers, linear_layers) = get_layers(arch='resnet32', model=model)\n",
    "for conv_layer in conv_layers:\n",
    "    conv_layer.weight = torch.nn.Parameter(conv_layer.weight * conv_layer.flag)\n",
    "\n",
    "for linear_layer in linear_layers:\n",
    "    linear_layer.weight = torch.nn.Parameter(linear_layer.weight * linear_layer.flag)\n",
    "\n",
    "sparsity = print_nonzeros(model, print_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bfe61e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Creating model 'resnet32'\n",
      "==> Conv Type: SubnetConv\n",
      "==> BN Type: NonAffineBatchNorm\n",
      "==> Building first layer\n",
      "==> Setting prune rate of network to 0.5\n",
      "=> Rough estimate model params 461872\n",
      "=> Freezing model weights\n",
      "=> Getting CIFAR10 dataset\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "model = get_model(parser_args)\n",
    "# model.load_state_dict(torch.load(PATH))\n",
    "data = get_dataset(parser_args)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "idty_str = get_idty_str(parser_args)\n",
    "if parser_args.subfolder is not None:\n",
    "    result_subroot = 'results/' + parser_args.subfolder + '/'\n",
    "    if not os.path.isdir(result_subroot):\n",
    "        os.mkdir(result_subroot)\n",
    "    result_root = result_subroot + '/results_' + idty_str + '/'\n",
    "else:\n",
    "    result_root = 'results/results_' + idty_str + '/'\n",
    "\n",
    "if not os.path.isdir(result_root):\n",
    "    os.mkdir(result_root)\n",
    "\n",
    "# test_random_subnet(model, data, criterion, parser_args, writer, result_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a740e62a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e02d3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(461872.)\n",
      "tensor(640.)\n",
      "61258752\n",
      "0.0001476523713705431\n"
     ]
    }
   ],
   "source": [
    "# how they do smart ratio\n",
    "\n",
    "# ========== calculate the sparsity using order statistics ============\n",
    "CNT = 0\n",
    "Num = []\n",
    "# ========== calculate the number of layers and the corresponding number of weights ============\n",
    "for idx, m in enumerate(model.modules()):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m,nn.Linear):\n",
    "        Num.append(m.weight.data.view(-1).size()[0])\n",
    "        CNT = CNT + 1\n",
    "\n",
    "Num = torch.from_numpy(np.array(Num)).float()  \n",
    "# tensor([  432.,  2304.,  2304.,  2304.,  2304.,  2304.,  2304.,  2304.,  2304.,\n",
    "#         2304.,  2304.,  4608.,  9216.,  9216.,  9216.,  9216.,  9216.,  9216.,\n",
    "#         9216.,  9216.,  9216., 18432., 36864., 36864., 36864., 36864., 36864.,\n",
    "#        36864., 36864., 36864., 36864.,   640.])\n",
    "\n",
    "# ========== set ratio ============\n",
    "n = CNT\n",
    "Ratio = torch.rand(1,CNT)\n",
    "for i in range(CNT):\n",
    "    k = i + 1 # 1~CNT\n",
    "    Ratio[0][n-k] = (k)**2 + k\n",
    "    \n",
    "Ratio = Ratio[0]\n",
    "num_now = 0\n",
    "total_num = 0\n",
    "linear_num = 0\n",
    "\n",
    "# ========== calculation and scaling ============\n",
    "i = 0\n",
    "TEST = 0\n",
    "for m in model.modules():\n",
    "    if isinstance(m,nn.Linear) or isinstance(m,nn.Conv2d):\n",
    "        if i < CNT - 1:\n",
    "            num_now = num_now + int((Ratio[i])*Num[i])\n",
    "            TEST = TEST + int(Num[i]*Ratio[i])\n",
    "        else:\n",
    "            linear_num = linear_num + Num[i]\n",
    "        total_num = total_num + Num[i]\n",
    "        i = i + 1\n",
    "\n",
    "init_prune_ratio = 0.98\n",
    "linear_keep_ratio = 0.3\n",
    "goal_num = int(total_num * (1-init_prune_ratio)) - int(linear_num*linear_keep_ratio)\n",
    "# ========== since the #linear_num is much lesser than that of total_num ============\n",
    "# ========== one can just easily set balance_ratio = 1 - init_prune_ratio without hurting the performance ============\n",
    "balance_ratio = goal_num / (total_num - linear_num)\n",
    "# print(balance_ratio)\n",
    "\n",
    "\n",
    "print(total_num)\n",
    "print(linear_num)\n",
    "print(TEST)\n",
    "# TEST\n",
    "k = (goal_num) / TEST\n",
    "print(k)\n",
    "i = 0\n",
    "for m in model.modules():\n",
    "    if isinstance(m,nn.Conv2d):\n",
    "        Ratio[i] = Ratio[i] * k\n",
    "        i = i + 1     \n",
    "\n",
    "        \n",
    "# # ========== if the prune-ratio is too small, then some keep_ratio will > 1 ============\n",
    "# # ========== the easy modification ============\n",
    "# ExtraNum = 0\n",
    "# i = 0\n",
    "# for m in model.modules():\n",
    "#     size = Num[i]\n",
    "#     if isinstance(m,nn.Linear) or isinstance(m,nn.Conv2d):\n",
    "#         if not isinstance(m,nn.Linear):\n",
    "#             if Ratio[i] >= 1:\n",
    "#                 ExtraNum = ExtraNum + int((Ratio[i]-1)*size)\n",
    "#                 Ratio[i] = 1\n",
    "#             else:\n",
    "#                 RestNum = int((1-Ratio[i])*Num[i])\n",
    "#                 if RestNum >= ExtraNum:\n",
    "#                     Ratio[i] = Ratio[i] + ExtraNum/Num[i]\n",
    "#                     ExtraNum = 0\n",
    "#                 else:\n",
    "#                     ExtraNum = ExtraNum - RestNum\n",
    "#                     Ratio[i] = 1\n",
    "#         if ExtraNum == 0:\n",
    "#             break\n",
    "#         i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b790dbd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c30b143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1559, 0.1465, 0.1373, 0.1285, 0.1199, 0.1116, 0.1037, 0.0960, 0.0886,\n",
       "        0.0815, 0.0747, 0.0682, 0.0620, 0.0561, 0.0505, 0.0452, 0.0402, 0.0354,\n",
       "        0.0310, 0.0269, 0.0230, 0.0195, 0.0162, 0.0133, 0.0106, 0.0083, 0.0062,\n",
       "        0.0044, 0.0030, 0.0018, 0.0009, 0.3000])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ratio[-1] = 0.3\n",
    "Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f49c1b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0200)\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "for i in range(CNT):\n",
    "    s += Num[i] * Ratio[i]\n",
    "\n",
    "print(s / 461872)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c092adc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ========== if the prune-ratio is too small, then some keep_ratio will > 1 ============\n",
    "# ========== the easy modification ============\n",
    "ExtraNum = 0\n",
    "i = 0\n",
    "for m in net.modules():\n",
    "    size = Num[i]\n",
    "    if isinstance(m,nn.Linear) or isinstance(m,nn.Conv2d):\n",
    "        if not isinstance(m,nn.Linear):\n",
    "            if Ratio[i] >= 1:\n",
    "                ExtraNum = ExtraNum + int((Ratio[i]-1)*size)\n",
    "                Ratio[i] = 1\n",
    "            else:\n",
    "                RestNum = int((1-Ratio[i])*Num[i])\n",
    "                if RestNum >= ExtraNum:\n",
    "                    Ratio[i] = Ratio[i] + ExtraNum/Num[i]\n",
    "                    ExtraNum = 0\n",
    "                else:\n",
    "                    ExtraNum = ExtraNum - RestNum\n",
    "                    Ratio[i] = 1\n",
    "        if ExtraNum == 0:\n",
    "            break\n",
    "        i = i + 1\n",
    "\n",
    "# ========== set the smart-ratio masks ============\n",
    "keep_masks = []\n",
    "CNT = 0\n",
    "\n",
    "for m in net.modules():\n",
    "    if isinstance(m,nn.Conv2d) or isinstance(m,nn.Linear):\n",
    "        mask = m.weight.data.abs().clone().float().cuda()\n",
    "        Size = mask.size()\n",
    "        mask = mask.view(-1)\n",
    "        keep_ratio = Ratio[CNT]\n",
    "        num_keep = int((keep_ratio)*Num[CNT])\n",
    "        if Ratio[CNT] >= 1:\n",
    "            num_keep = int(Num[CNT])\n",
    "        if args.uniform != 0:\n",
    "            Ratio[CNT] = balance_ratio\n",
    "            num_keep = int(Ratio[CNT]*Num[CNT])\n",
    "        if isinstance(m,nn.Linear):\n",
    "            num_keep = int(linear_keep_ratio*Num[CNT])\n",
    "        # ========== this judgement is for our hybrid ticket ============\n",
    "        # ========== if specify the hybrid method, our smart ratio will combine the magnitude-based pruning ============\n",
    "        if args.hybrid != 0:\n",
    "            print(\"################### DEBUG PRINT : USING HYBRID TICKET ###################\")\n",
    "            value,idx = torch.topk(mask,num_keep)\n",
    "            temp = torch.zeros(int(Num[CNT]))\n",
    "            temp[idx] = 1.0\n",
    "            mask = temp.clone().float().cuda()\n",
    "\n",
    "        else:\n",
    "            temp = torch.ones(1,num_keep)\n",
    "            mask[0:num_keep] = temp\n",
    "            temp = torch.zeros(1,int(Num[CNT].item()-num_keep))\n",
    "            mask[num_keep:] = temp\n",
    "            mask = mask.view(-1)[torch.randperm(mask.nelement())].view(mask.size())\n",
    "\n",
    "\n",
    "\n",
    "        CNT = CNT + 1\n",
    "        keep_masks.append(mask.view(Size))\n",
    "\n",
    "\n",
    "return keep_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7577a5aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c88303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# round the score (in the model itself)\n",
    "model = round_model(model, round_scheme=\"all_ones\", noise=parser_args.noise, ratio=parser_args.noise_ratio, rank=parser_args.gpu)    \n",
    "\n",
    "# TODO: CHANGE THIS BACK once the finetune from checkpoints code is fixed\n",
    "# NOTE: this part is hard coded\n",
    "# model = redraw(model, shuffle=parser_args.shuffle, reinit=parser_args.reinit, chg_mask=parser_args.chg_mask, chg_weight=parser_args.chg_weight)  \n",
    "\n",
    "# switch to weight training mode (turn on the requires_grad for weight/bias, and turn off the requires_grad for other parameters)\n",
    "model = switch_to_wt(model)\n",
    "\n",
    "run_base_dir, ckpt_base_dir, log_base_dir, writer, epoch_time, validation_time, train_time, progress_overall = get_settings(parser_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772f364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if parser_args.random_network_per_layer_ratio is not None:\n",
    "    idx = 0\n",
    "    conv_layers, linear_layers = get_layers(arch='resnet20', model=model)\n",
    "    for layer in conv_layers:\n",
    "        N = np.prod(layer.weight.shape)\n",
    "        K = int(parser_args.random_network_per_layer_ratio[idx] / 100. * N)\n",
    "        tmp_array = np.array([0] * (N-K) + [1] * K)\n",
    "        np.random.shuffle(tmp_array)\n",
    "        layer.flag = torch.nn.Parameter(torch.from_numpy(tmp_array).float().reshape(layer.weight.shape))\n",
    "        idx += 1\n",
    "    for layer in linear_layers:\n",
    "        N = np.prod(layer.weight.shape)\n",
    "        K = int(parser_args.random_network_per_layer_ratio[idx] / 100. * N)\n",
    "        tmp_array = np.array([0] * (N-K) + [1] * K)\n",
    "        np.random.shuffle(tmp_array)\n",
    "        layer.flag = torch.nn.Parameter(torch.from_numpy(tmp_array).float().reshape(layer.weight.shape))\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49103ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (conv_layers, linear_layers) = get_layers(arch='resnet20', model=model)\n",
    "# for conv_layer in conv_layers:\n",
    "#     conv_layer.weight = torch.nn.Parameter(conv_layer.weight * conv_layer.flag)\n",
    "\n",
    "# for linear_layer in linear_layers:\n",
    "#     linear_layer.weight = torch.nn.Parameter(linear_layer.weight * linear_layer.flag)\n",
    "\n",
    "# hc_sparsity = print_nonzeros(model, print_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c187ceba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48b260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = get_optimizer(parser_args, model, finetune_flag=True)\n",
    "scheduler = get_scheduler(optimizer, parser_args.fine_tune_lr_policy) \n",
    "train, validate, modifier = get_trainer(parser_args)\n",
    "model = set_gpu(parser_args, model)\n",
    "writer = None\n",
    "\n",
    "# check the performance of loaded model (after rounding)\n",
    "acc1, acc5, acc10 = validate(data.val_loader, model, criterion, parser_args, writer, parser_args.epochs-1)\n",
    "epoch_list = []\n",
    "test_acc_before_round_list = []\n",
    "test_acc_list = []\n",
    "reg_loss_list = []\n",
    "# model_sparsity_list = []\n",
    "\n",
    "for epoch in range(parser_args.epochs):\n",
    "\n",
    "    if parser_args.multiprocessing_distributed:\n",
    "        data.train_loader.sampler.set_epoch(epoch)\n",
    "    cur_lr = get_lr(optimizer)\n",
    "    print('epoch: {}, lr: {}'.format(epoch, cur_lr))\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # train for one epoch\n",
    "    start_train = time.time()\n",
    "    train_acc1, train_acc5, train_acc10, reg_loss = train(\n",
    "        data.train_loader, model, criterion, optimizer, epoch, parser_args, writer=writer\n",
    "    )\n",
    "    train_time.update((time.time() - start_train) / 60)\n",
    "    scheduler.step()\n",
    "\n",
    "    # evaluate on validation set\n",
    "    start_validation = time.time()\n",
    "    acc1, acc5, acc10 = validate(data.val_loader, model, criterion, parser_args, writer, epoch)\n",
    "    validation_time.update((time.time() - start_validation) / 60)\n",
    "    # cp_model = round_model(model, parser_args.round, noise=parser_args.noise, ratio=parser_args.noise_ratio, rank=parser_args.gpu)\n",
    "    # avg_sparsity = get_model_sparsity(cp_model)\n",
    "    # print('Model avg sparsity: {}'.format(avg_sparsity))\n",
    "\n",
    "    # update all results lists\n",
    "    epoch_list.append(epoch)\n",
    "    test_acc_before_round_list.append(-1)\n",
    "    test_acc_list.append(acc1)\n",
    "    reg_loss_list.append(reg_loss)\n",
    "    # model_sparsity_list.append(avg_sparsity)\n",
    "\n",
    "    epoch_time.update((time.time()) / 60)\n",
    "#     progress_overall.display(epoch)\n",
    "#     progress_overall.write_to_tensorboard(\n",
    "#         writer, prefix=\"diagnostics\", global_step=epoch\n",
    "#     )\n",
    "#     writer.add_scalar(\"test/lr\", cur_lr, epoch)\n",
    "    end_epoch = time.time()\n",
    "\n",
    "    results_df = pd.DataFrame({'epoch': epoch_list, 'test_acc_before_rounding': test_acc_before_round_list,'test_acc': test_acc_list, 'regularization_loss': reg_loss_list})# , 'model_sparsity': model_sparsity_list})\n",
    "\n",
    "    if parser_args.results_filename:\n",
    "        results_filename = parser_args.results_filename\n",
    "    else:\n",
    "        results_filename = result_root + 'random_subnet_{}.csv'.format(parser_args.prune_rate)\n",
    "    print(\"Writing results into: {}\".format(results_filename))\n",
    "    results_df.to_csv(results_filename, index=False)\n",
    "\n",
    "if parser_args.multiprocessing_distributed:\n",
    "    cleanup_distributed()\n",
    "\n",
    "# save checkpoint for later debug\n",
    "print(\"Writing final model to {}\".format(model_filename))\n",
    "torch.save(model.state_dict(), model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27860df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(conv_layers, linear_layers) = get_layers(arch='resnet20', model=model)\n",
    "for conv_layer in conv_layers:\n",
    "    conv_layer.weight = torch.nn.Parameter(conv_layer.weight * conv_layer.flag)\n",
    "\n",
    "for linear_layer in linear_layers:\n",
    "    linear_layer.weight = torch.nn.Parameter(linear_layer.weight * linear_layer.flag)\n",
    "\n",
    "hc_sparsity = print_nonzeros(model, print_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5f4ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee4052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, target in test_loader:\n",
    "            x, target = x.to(device), target.to(device)\n",
    "            output = model(x)\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_acc = 100. * correct/len(test_loader.dataset)\n",
    "    return test_acc\n",
    "\n",
    "\n",
    "data = get_dataset(parser_args)\n",
    "test(model, \"cuda\", data.val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee2231a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd11ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
