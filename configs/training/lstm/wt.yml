#subfolder: lstm_WT_runs
trial_num: 1

# algorithm
algo: 'hc_iter'
weight_training: True
bias: True

# Architecture
arch: RNNModel

# ===== Dataset ===== #
dataset: Wiki
name: lstm_wiki_training

# ===== Learning Rate Policy ======== #
optimizer: sgd
lr: 20
fine_tune_lr: 20
lr_policy: constant_lr #multistep_lr #cosine_lr #constant_lr

# ===== Network training config ===== #
epochs: 40
wd: 0 #0.0005
momentum: 0 #0.9
batch_size: 20
eval_batch_size: 10
target_sparsity: 100

# ===== Sparsity =========== #
conv_type: SubnetConv
bn_type: NonAffineBatchNorm
freeze_weights: True
#prune_rate: -1
init: kaiming_normal #signed_constant
scale_fan: True
skip_fine_tune: True

# ===== Hardware setup ===== #
workers: 4
#gpu: 0
