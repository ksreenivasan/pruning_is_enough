subfolder: lstm_WT_runs
trial_num: 1

# algorithm
algo: 'hc_iter'
weight_training: True

# Architecture
arch: vgg16 #lstm

# ===== Dataset ===== #
dataset: Wiki
name: lstm_wiki_training

# ===== Learning Rate Policy ======== #
optimizer: sgd
#lr: 0.1
fine_tune_lr: 0.01
lr_policy: multistep_lr #cosine_lr #constant_lr

# ===== Network training config ===== #
epochs: 40
wd: 0.0005
momentum: 0.9
batch_size: 128
target_sparsity: 100
weight_training: True

# ===== Sparsity =========== #
conv_type: SubnetConv
bn_type: NonAffineBatchNorm
freeze_weights: True
#prune_rate: -1
init: signed_constant
scale_fan: True
skip_fine_tune: True

# ===== Hardware setup ===== #
workers: 4
gpu: 0
